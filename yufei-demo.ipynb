{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClinicalBert: Hospital Admission Prediction with Discharge Note "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMIC-IV: Discharge summary and ED stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ED stay data\n",
    "# !wget -r -N -c -np --user yudeng98 --ask-password https://physionet.org/files/mimic-iv-ed/2.2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discharge summary dataset\n",
    "discharge = pd.read_csv('data/note/discharge.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"',  keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge.dropna(subset=['hadm_id'], inplace=True)\n",
    "df_target = discharge[discharge['text'].str.contains('Discharge Instruction') & discharge['text'].str.contains('Brief Hospital Course')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/17sr6ctn7t59v0xfhzjh4l380000gn/T/ipykernel_9855/1832240310.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target['discharge_instructions'] = df_target['text'].apply(lambda x: re.findall(r'Discharge Instructions:\\n(.*?)Followup Instruction', x, re.DOTALL))\n",
      "/var/folders/tz/17sr6ctn7t59v0xfhzjh4l380000gn/T/ipykernel_9855/1832240310.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target['discharge_instructions'] = df_target['discharge_instructions'].apply(lambda x: [i.strip() for i in x])\n"
     ]
    }
   ],
   "source": [
    "## Select only those with Brief Hospital Course and Discharge Instructions in the note\n",
    "# note: \"Brief Hospital Course\" section is usually located in the middle of the discharge summary\n",
    "# following information about patient history and treatments received during the current visit.\n",
    "# The \"Discharge Instructions\" section is generally located the end of the note as one of the last sections.\n",
    "df_target['discharge_instructions'] = df_target['text'].apply(lambda x: re.findall(r'Discharge Instructions:\\n(.*?)Followup Instruction', x, re.DOTALL))\n",
    "df_target['discharge_instructions'] = df_target['discharge_instructions'].apply(lambda x: [i.strip() for i in x])\n",
    "df_target = df_target[df_target['discharge_instructions'].str.len() == 1]\n",
    "df_target['discharge_instructions'].str.len().value_counts()\n",
    "df_target = df_target.explode('discharge_instructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You were admitted to the hospital for inflammation in the liver \n",
      "that was likely due to alcohol consumption. You were treated \n",
      "supportively with nutrition and also treated with medicines for \n",
      "alcohol withdrawal. We monitored your liver function daily with \n",
      "blood tests and found that the liver function was improving at \n",
      "time of discharge. During this admission, you were also found to \n",
      "have a urinary tract infection and a pneumonia. Please complete \n",
      "five more days of antibiotics (levofloxacin) to treat these \n",
      "infections.\n",
      "\n",
      "We have started a new medicine that will help remove fluid from \n",
      "the abdomen and legs. This medicine is called spironolactone. \n",
      "Since this medicine can raise potassium levels in the blood, we \n",
      "would like you to have your blood-work checked next ___. \n",
      "You can have this done at ___ in the Atrium Suite on the first floor or on \n",
      "the sixth floor, anytime from 8am to 6pm.\n",
      "\n",
      "We made the following changes to your medicines:\n",
      "- we ADDED folate, thiamine, and multivitamin (for general \n",
      "nutrition)\n",
      "- we ADDED lidocaine patch (for pain)\n",
      "- we ADDED nicotine patch\n",
      "- we ADDED levofloxacin (antibiotic for pneumonia)\n",
      "- we ADDED spironolactone (diuretic to prevent fluid \n",
      "accumulation)\n",
      "There were no other changes to your medicines.\n",
      "\n",
      "Please see the appointments that we have scheduled for you \n",
      "below.\n"
     ]
    }
   ],
   "source": [
    "print(df_target['discharge_instructions'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClinicalBert - Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_adm = pd.read_csv('/Users/KexinHuang/Downloads/ADMISSIONS.csv')\n",
    "df_adm.ADMITTIME = pd.to_datetime(df_adm.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "df_adm.DISCHTIME = pd.to_datetime(df_adm.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "df_adm.DEATHTIME = pd.to_datetime(df_adm.DEATHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "df_adm = df_adm.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "df_adm = df_adm.reset_index(drop = True)\n",
    "df_adm['NEXT_ADMITTIME'] = df_adm.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
    "df_adm['NEXT_ADMISSION_TYPE'] = df_adm.groupby('SUBJECT_ID').ADMISSION_TYPE.shift(-1)\n",
    "\n",
    "rows = df_adm.NEXT_ADMISSION_TYPE == 'ELECTIVE'\n",
    "df_adm.loc[rows,'NEXT_ADMITTIME'] = pd.NaT\n",
    "df_adm.loc[rows,'NEXT_ADMISSION_TYPE'] = np.NaN\n",
    "\n",
    "df_adm = df_adm.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "\n",
    "#When we filter out the \"ELECTIVE\", we need to correct the next admit time for these admissions since there might be 'emergency' next admit after \"ELECTIVE\"\n",
    "df_adm[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']] = df_adm.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']].fillna(method = 'bfill')\n",
    "df_adm['DAYS_NEXT_ADMIT']=  (df_adm.NEXT_ADMITTIME - df_adm.DISCHTIME).dt.total_seconds()/(24*60*60)\n",
    "df_adm['OUTPUT_LABEL'] = (df_adm.DAYS_NEXT_ADMIT < 30).astype('int')\n",
    "### filter out newborn and death\n",
    "df_adm = df_adm[df_adm['ADMISSION_TYPE']!='NEWBORN']\n",
    "df_adm = df_adm[df_adm.DEATHTIME.isnull()]\n",
    "df_adm['DURATION'] = (df_adm['DISCHTIME']-df_adm['ADMITTIME']).dt.total_seconds()/(24*60*60)\n",
    "\n",
    "df_notes = pd.read_csv('/Users/KexinHuang/Downloads/NOTEEVENTS.csv')\n",
    "df_notes = df_notes.sort_values(by=['SUBJECT_ID','HADM_ID','CHARTDATE'])\n",
    "df_adm_notes = pd.merge(df_adm[['SUBJECT_ID','HADM_ID','ADMITTIME','DISCHTIME','DAYS_NEXT_ADMIT','NEXT_ADMITTIME','ADMISSION_TYPE','DEATHTIME','OUTPUT_LABEL','DURATION']],\n",
    "                        df_notes[['SUBJECT_ID','HADM_ID','CHARTDATE','TEXT','CATEGORY']], \n",
    "                        on = ['SUBJECT_ID','HADM_ID'],\n",
    "                        how = 'left')\n",
    "\n",
    "df_adm_notes.ADMITTIME_C = df_adm_notes.ADMITTIME.apply(lambda x: str(x).split(' ')[0])\n",
    "df_adm_notes['ADMITTIME_C'] = pd.to_datetime(df_adm_notes.ADMITTIME_C, format = '%Y-%m-%d', errors = 'coerce')\n",
    "df_adm_notes['CHARTDATE'] = pd.to_datetime(df_adm_notes.CHARTDATE, format = '%Y-%m-%d', errors = 'coerce')\n",
    "\n",
    "### If Discharge Summary \n",
    "df_discharge = df_adm_notes[df_adm_notes['CATEGORY'] == 'Discharge summary']\n",
    "# multiple discharge summary for one admission -> after examination -> replicated summary -> replace with the last one \n",
    "df_discharge = (df_discharge.groupby(['SUBJECT_ID','HADM_ID']).nth(-1)).reset_index()\n",
    "df_discharge=df_discharge[df_discharge['TEXT'].notnull()]\n",
    "\n",
    "### If Less than n days on admission notes (Early notes)\n",
    "def less_n_days_data (df_adm_notes, n):\n",
    "    \n",
    "    df_less_n = df_adm_notes[((df_adm_notes['CHARTDATE']-df_adm_notes['ADMITTIME_C']).dt.total_seconds()/(24*60*60))<n]\n",
    "    df_less_n=df_less_n[df_less_n['TEXT'].notnull()]\n",
    "    #concatenate first\n",
    "    df_concat = pd.DataFrame(df_less_n.groupby('HADM_ID')['TEXT'].apply(lambda x: \"%s\" % ' '.join(x))).reset_index()\n",
    "    df_concat['OUTPUT_LABEL'] = df_concat['HADM_ID'].apply(lambda x: df_less_n[df_less_n['HADM_ID']==x].OUTPUT_LABEL.values[0])\n",
    "\n",
    "    return df_concat\n",
    "\n",
    "df_less_2 = less_n_days_data(df_adm_notes, 2)\n",
    "df_less_3 = less_n_days_data(df_adm_notes, 3)\n",
    "\n",
    "\n",
    "def preprocess1(x):\n",
    "    y=re.sub('\\\\[(.*?)\\\\]','',x) #remove de-identified brackets\n",
    "    y=re.sub('[0-9]+\\.','',y) #remove 1.2. since the segmenter segments based on this\n",
    "    y=re.sub('dr\\.','doctor',y)\n",
    "    y=re.sub('m\\.d\\.','md',y)\n",
    "    y=re.sub('admission date:','',y)\n",
    "    y=re.sub('discharge date:','',y)\n",
    "    y=re.sub('--|__|==','',y)\n",
    "    return y\n",
    "\n",
    "def preprocessing(df_less_n): \n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].fillna(' ')\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].str.replace('\\n',' ')\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].str.replace('\\r',' ')\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].apply(str.strip)\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].str.lower()\n",
    "\n",
    "    df_less_n['TEXT']=df_less_n['TEXT'].apply(lambda x: preprocess1(x))\n",
    "\n",
    "    #to get 318 words chunks for readmission tasks\n",
    "    from tqdm import tqdm\n",
    "    df_len = len(df_less_n)\n",
    "    want=pd.DataFrame({'ID':[],'TEXT':[],'Label':[]})\n",
    "    for i in tqdm(range(df_len)):\n",
    "        x=df_less_n.TEXT.iloc[i].split()\n",
    "        n=int(len(x)/318)\n",
    "        for j in range(n):\n",
    "            want=want.append({'TEXT':' '.join(x[j*318:(j+1)*318]),'Label':df_less_n.OUTPUT_LABEL.iloc[i],'ID':df_less_n.HADM_ID.iloc[i]},ignore_index=True)\n",
    "        if len(x)%318>10:\n",
    "            want=want.append({'TEXT':' '.join(x[-(len(x)%318):]),'Label':df_less_n.OUTPUT_LABEL.iloc[i],'ID':df_less_n.HADM_ID.iloc[i]},ignore_index=True)\n",
    "    \n",
    "    return want\n",
    "\n",
    "df_discharge = preprocessing(df_discharge)\n",
    "df_less_2 = preprocessing(df_less_2)\n",
    "df_less_3 = preprocessing(df_less_3)\n",
    "\n",
    "### An example to get the train/test/split with random state:\n",
    "### note that we divide on patient admission level and share among experiments, instead of notes level. \n",
    "### This way, since our methods run on the same set of admissions, we can see the\n",
    "### progression of readmission scores. \n",
    "\n",
    "readmit_ID = df_adm[df_adm.OUTPUT_LABEL == 1].HADM_ID\n",
    "not_readmit_ID = df_adm[df_adm.OUTPUT_LABEL == 0].HADM_ID\n",
    "#subsampling to get the balanced pos/neg numbers of patients for each dataset\n",
    "not_readmit_ID_use = not_readmit_ID.sample(n=len(readmit_ID), random_state=1)\n",
    "id_val_test_t=readmit_ID.sample(frac=0.2,random_state=1)\n",
    "id_val_test_f=not_readmit_ID_use.sample(frac=0.2,random_state=1)\n",
    "\n",
    "id_train_t = readmit_ID.drop(id_val_test_t.index)\n",
    "id_train_f = not_readmit_ID_use.drop(id_val_test_f.index)\n",
    "\n",
    "id_val_t=id_val_test_t.sample(frac=0.5,random_state=1)\n",
    "id_test_t=id_val_test_t.drop(id_val_t.index)\n",
    "\n",
    "id_val_f=id_val_test_f.sample(frac=0.5,random_state=1)\n",
    "id_test_f=id_val_test_f.drop(id_val_f.index)\n",
    "\n",
    "# test if there is overlap between train and test, should return \"array([], dtype=int64)\"\n",
    "(pd.Index(id_test_t).intersection(pd.Index(id_train_t))).values\n",
    "\n",
    "id_test = pd.concat([id_test_t, id_test_f])\n",
    "test_id_label = pd.DataFrame(data = list(zip(id_test, [1]*len(id_test_t)+[0]*len(id_test_f))), columns = ['id','label'])\n",
    "\n",
    "id_val = pd.concat([id_val_t, id_val_f])\n",
    "val_id_label = pd.DataFrame(data = list(zip(id_val, [1]*len(id_val_t)+[0]*len(id_val_f))), columns = ['id','label'])\n",
    "\n",
    "id_train = pd.concat([id_train_t, id_train_f])\n",
    "train_id_label = pd.DataFrame(data = list(zip(id_train, [1]*len(id_train_t)+[0]*len(id_train_f))), columns = ['id','label'])\n",
    "\n",
    "#get discharge train/val/test\n",
    "\n",
    "discharge_train = df_discharge[df_discharge.ID.isin(train_id_label.id)]\n",
    "discharge_val = df_discharge[df_discharge.ID.isin(val_id_label.id)]\n",
    "discharge_test = df_discharge[df_discharge.ID.isin(test_id_label.id)]\n",
    "\n",
    "# subsampling for training....since we obtain training on patient admission level so now we have same number of pos/neg readmission\n",
    "# but each admission is associated with different length of notes and we train on each chunks of notes, not on the admission, we need\n",
    "# to balance the pos/neg chunks on training set. (val and test set are fine) Usually, positive admissions have longer notes, so we need \n",
    "# find some negative chunks of notes from not_readmit_ID that we haven't used yet\n",
    "\n",
    "df = pd.concat([not_readmit_ID_use, not_readmit_ID])\n",
    "df = df.drop_duplicates(keep=False)\n",
    "#check to see if there are overlaps\n",
    "(pd.Index(df).intersection(pd.Index(not_readmit_ID_use))).values\n",
    "\n",
    "# for this set of split with random_state=1, we find we need 400 more negative training samples\n",
    "not_readmit_ID_more = df.sample(n=400, random_state=1)\n",
    "discharge_train_snippets = pd.concat([df_discharge[df_discharge.ID.isin(not_readmit_ID_more)], discharge_train])\n",
    "\n",
    "#shuffle\n",
    "discharge_train_snippets = discharge_train_snippets.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "#check if balanced\n",
    "discharge_train_snippets.Label.value_counts()\n",
    "\n",
    "discharge_train_snippets.to_csv('./discharge/train.csv')\n",
    "discharge_val.to_csv('./discharge/val.csv')\n",
    "discharge_test.to_csv('./discharge/test.csv')\n",
    "\n",
    "### for Early notes experiment: we only need to find training set for 3 days, then we can test \n",
    "### both 3 days and 2 days. Since we split the data on patient level and experiments share admissions\n",
    "### in order to see the progression, the 2 days training dataset is a subset of 3 days training set.\n",
    "### So we only train 3 days and we can test/val on both 2 & 3days or any time smaller than 3 days. This means\n",
    "### if we train on a dataset with all the notes in n days, we can predict readmissions smaller than n days. \n",
    "\n",
    "#for 3 days note, similar to discharge\n",
    "\n",
    "early_train = df_less_3[df_less_3.ID.isin(train_id_label.id)]\n",
    "not_readmit_ID_more = df.sample(n=500, random_state=1)\n",
    "early_train_snippets = pd.concat([df_less_3[df_less_3.ID.isin(not_readmit_ID_more)], early_train])\n",
    "#shuffle\n",
    "early_train_snippets = early_train_snippets.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "early_train_snippets.to_csv('./3days/train.csv')\n",
    "\n",
    "early_val = df_less_3[df_less_3.ID.isin(val_id_label.id)]\n",
    "early_val.to_csv('./3days/val.csv')\n",
    "\n",
    "# we want to test on admissions that are not discharged already. So for less than 3 days of notes experiment,\n",
    "# we filter out admissions discharged within 3 days\n",
    "actionable_ID_3days = df_adm[df_adm['DURATION'] >= 3].HADM_ID\n",
    "test_actionable_id_label = test_id_label[test_id_label.id.isin(actionable_ID_3days)]\n",
    "early_test = df_less_3[df_less_3.ID.isin(test_actionable_id_label.id)]\n",
    "\n",
    "early_test.to_csv('./3days/test.csv')\n",
    "\n",
    "#for 2 days notes, we only obtain test set. Since the model parameters are tuned on the val set of 3 days\n",
    "\n",
    "actionable_ID_2days = df_adm[df_adm['DURATION'] >= 2].HADM_ID\n",
    "\n",
    "test_actionable_id_label_2days = test_id_label[test_id_label.id.isin(actionable_ID_2days)]\n",
    "\n",
    "early_test_2days = df_less_2[df_less_2.ID.isin(test_actionable_id_label_2days.id)]\n",
    "\n",
    "early_test_2days.to_csv('./2days/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
